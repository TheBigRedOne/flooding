\documentclass[10pt,conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{url}
\newcommand{\todo}[1]{\textbf{\textcolor{red}{To do: #1}}}
\newcommand{\csp}[1]{\textbf{\textcolor{purple}{CSP: #1}}}
\newcommand{\ryo}[1]{\textbf{\textcolor{teal}{RY: #1}}}

\graphicspath{{figures/}}

\makeatletter
\newcommand{\linebreakand}{%
  \end{@IEEEauthorhalign}
  \hfill\mbox{}\par
  \mbox{}\hfill\begin{@IEEEauthorhalign}
}
\makeatother

\begin{document}

\title{OptoFlood: Controllable Flooding for NDN Producer Mobility}

\author{
    \IEEEauthorblockN{Yuting Wan}
    \IEEEauthorblockA{University of Glasgow\\
    yuting.wan@glasgow.ac.uk}
\and
    \IEEEauthorblockN{Ryo Yanagida}
    \IEEEauthorblockA{University of Glasgow\\
    ryo@htonl.net}
\and
    \IEEEauthorblockN{Paul Harvey}
    \IEEEauthorblockA{University of Glasgow\\
    paul.harvey@glasgow.ac.uk}
\linebreakand
    \IEEEauthorblockN{Jeremy Singer}
    \IEEEauthorblockA{University of Glasgow\\
    jeremy.singer@glasgow.ac.uk}
\and
    \IEEEauthorblockN{Colin Perkins}
    \IEEEauthorblockA{University of Glasgow\\
    csp@csperkins.org}
\and
    \IEEEauthorblockN{Leon Wong}
    \IEEEauthorblockA{Rakuten Mobile, Inc.\\
    leon.wong@rakuten.com}
}

\maketitle

% ==============================================================================

\begin{abstract}

Producer mobility in systems that use Named Data Networking (NDN) protocols can lead to increased latency and packet loss due to slow routing convergence and stale forwarding state. This affects applications, such as live video streaming and video conferencing, where even a brief interruption in packet delivery can degrade user experience. To address this, we propose \textit{OptoFlood}, a controllable flooding mechanism that supports both Data and Interest delivery immediately following producer movement events, to rapidly establish temporary bidirectional communication paths. In OptoFlood, mobility-marked packets are disseminated with bounded scope, deduplication, and rate limiting, while intermediate nodes create short-lived forwarding hints via a temporary FIB (TFIB). When forwarding fails due to both FIB and TFIB misses, the Forwarder triggers a hop-limited flooding procedure to discover viable paths. OptoFlood also accelerates global routing convergence through Fast-LSA. Our evaluation demonstrates that OptoFlood effectively reduces latency and packet loss caused by producer mobility while maintaining reasonable network overhead.

\end{abstract}

% ==============================================================================

\begin{IEEEkeywords}
Named Data Networking, Producer Mobility, Controlled Flooding, TFIB, NLSR
\end{IEEEkeywords}

% ==============================================================================

\section{Introduction}
\label{sec:introduction}

% Paragraph 1: Motivation.
The use of Named Data Networking (NDN) protocols optimises the network for content delivery. Rather than relying on an indirect name-to-location mapping via the DNS, as is done in the Internet today, NDN protocols make name-based routing, content delivery, and pervasive caching core services of the network.

% Paragraph 2: Specific problem.
However, a limitation of current NDN protocols is that they do not effectively support producer mobility. Each time a content producer moves, the network must quickly discover its new location and ensure continuous data delivery without introducing delays or packet loss. For applications such as live video streaming and video conferencing, even short interruptions can degrade user experience and reliability. In practice, producer movement invalidates previously valid forwarding paths, while routing updates may take seconds to converge. During this period, Interest packets can be misrouted, timed out, or discarded due to a stale forwarding state. Previous works have improved the behaviour of NDN in these scenarios, but still lag behind what is needed \cite{abrar:2023:systematic}.

% Paragraph 3: Contributions.
In this paper, we introduce OptoFlood, a novel controlled flooding scheme that can establish temporary bidirectional communication paths to accelerate network convergence after producer mobility events. OptoFlood proactively manages controlled local flooding of both \emph{Data} and \emph{Interest} packets, enabling rapid recovery from disruptions caused by producer movements. 

Specifically, OptoFlood includes two complementary components.

First, after a producer movement event, the producer performs \emph{Data packet flooding} for mobility-marked Data corresponding to pending Interests. This flooding is explicitly bounded (e.g., hop-limited) and rate controlled, and is intended to quickly ``push'' Data across nearby nodes so that Interests that would otherwise stall can be satisfied without waiting for global routing convergence.
Second, when forwarding fails because both the FIB and a temporary forwarding table (TFIB) provide no usable next hop, forwarders trigger a hop-limited \emph{Interest packet flooding} procedure to promptly rediscover viable paths toward the producer's new attachment point. Intermediate nodes opportunistically create short-lived TFIB hints based on newly observed forwarding opportunities, which helps suppress repeated flooding and restore unicast forwarding quickly.

OptoFlood also integrates with Named-data Link State Routing (NLSR) by generating short-lived routing updates based on newly established temporary paths (Fast-LSA), which accelerates global routing convergence. Collectively, these mechanisms reduce latency and packet loss while maintaining reasonable overhead in network resource usage.

% Paragraph 4: Comparison to related work.
Compared to previous NDN mobility protocols, such as routing-based updates \cite{meddeb:2018:afirm}, Interest-based notification solutions \cite{auge:2016:map-me} or anchor-based tracing mechanisms \cite{zhang:2018:kite}, OptoFlood provides a more integrated and lightweight solution that leverages flooding as its primary mechanism for rapid path recovery and convergence. Unlike existing flooding solutions, our approach uses explicit controls, including hop limits, deduplication within a short time window, and producer-side flood rate limits, to restrict the scope and duration of flooding, minimising unnecessary overhead. Additionally, by leveraging temporary bidirectional paths established via controlled flooding and propagating them through short-lived routing updates, OptoFlood accelerates global routing convergence without relying on centralised anchor nodes.

% Paragraph 5: Roadmap.
We structure the remainder of this paper as follows. Section \ref{sec:problem} reviews the background of producer mobility problems in NDN, highlighting the limitations of traditional routing updates. Section \ref{sec:solution} presents the detailed design of OptoFlood, including the mechanisms for controlled flooding of Data and Interest packets, and the integration with NLSR to accelerate global convergence. Section \ref{sec:evaluation} describes our experimental setup and presents results that demonstrate the effectiveness of our approach.
We discuss related work in Section \ref{sec:related}.
Finally, Section \ref{sec:conclusion} concludes the paper and briefly discusses potential directions for future enhancements of the OptoFlood approach.

% ==============================================================================

\section{Producer Mobility in NDN}
\label{sec:problem}

NDN shifts from a host-centric model to a data-centric model, where content is identified by names rather than addresses. In NDN, communication relies on two core packet types: Interest Packets, sent by consumers to request data by specifying the content name, and Data Packets, returned by producers containing the requested content and related metadata. Both packet types follow a concise Type-Length-Value (TLV) encoding, enabling efficient processing and extendability.

NDN packet forwarders maintain a Content Store that caches Data packets; a Pending Interest Table (PIT) that records forwarded Interest packets awaiting the corresponding Data packets, ensuring accurate reverse path forwarding; and a Forwarding Information Base (FIB) that guides Interest packet forwarding.
When an Interest arrives at a forwarder, it checks the Content Store and returns the cached Data, if it is available. Otherwise, the PIT is checked to aggregate Interests, and if the Interest is new, it is forwarded based on the FIB. Figure~\ref{fig:NDN Packets Processing Flow} illustrates packet forwarding.

\begin{figure}[t]
    \centering
    \includegraphics[width=1\linewidth]{NDN_Packets_Processing_Flow.pdf}
    \caption{NDN Packets Processing Flow}
    \label{fig:NDN Packets Processing Flow}
\end{figure}

The Named-Data Link State Routing protocol (NLSR) disseminates routing information via Link State Advertisements (LSAs) that carry link status and available data prefix information that are used to populate the FIB. NLSR adapts to network changes, such as node failures, new node attachments, or topology changes through periodic updates.

Producer mobility in NDN poses significant challenges, especially in dynamic environments. When a producer moves, it must re-register its data prefix so that NLSR can propagate the new route. Convergence is not immediate and is slow relative to mobility. During the convergence period, Interests may continue to follow stale forwarding state towards the producer's previous attachment point, while the producer begins responding at the new location. This mismatch can leave pre-move Interests pending for an extended time, and can also prevent newly generated Data from being returned successfully along the reverse path. Figure~\ref{fig:NDN Producer Mobility Problem} provides an illustrative example of this handover behaviour.

\begin{figure}[t]
    \centering
    \includegraphics[width=1\linewidth]{NDN_Producer_Mobility_Problem.pdf}
    \caption{NDN Producer Mobility Problem}
    \label{fig:NDN Producer Mobility Problem}
\end{figure}

This results in the following.
\begin{itemize}
\item \textbf{Increased Latency:} When a producer changes its attachment point, its associated data prefixes must be re-advertised, initiating routing updates starting from the directly connected forwarder. These updates must propagate throughout the network before Interest Packets can be delivered to the producer at its new location. During this convergence period, consumers experience significant communication interruptions, often lasting several seconds or longer \cite{abrar:2023:systematic}. In scenarios requiring low latency, such as live video streaming or real-time conferencing, even brief interruptions degrade the user experience and severely limit the practical utility of NDN \cite{abrar:2023:systematic}. Figure~\ref{fig:NDN Producer Mobility Problem} illustrates how the service resumes only after the routing information has propagated sufficiently for Interests to reach the new attachment point.

\item \textbf{Packet Loss:} During producer relocation and the subsequent routing convergence process, Interest packets following stale forwarding state may be unable to reach the producer's new location, causing these packets to expire and be discarded. Additionally, Data packets generated in response to Interests that were issued shortly before relocation may fail to return successfully if the reverse path state has been invalidated. In particular, Data may encounter forwarders that do not have a matching PIT entry (e.g., because the Interest was forwarded along a different path, or because the PIT state has timed out), leading to dropped Data and further degradation of communication reliability.

\item \textbf{Increased Network Resource Usage:} Inefficiencies introduced by latency and packet loss also result in increased retransmissions of packets of Interest. These retransmissions consume additional bandwidth and processing resources across the network, potentially impacting overall network performance and affecting other communications.
\end{itemize}

To further illustrate the impact of slow convergence on producer mobility, we include baseline measurements from our experimental setup. Figures~\ref{fig:baseline_throughput} and~\ref{fig:baseline_disruption} show that the movement of the producers can cause a clear disruption period in which throughput decreases and recovery is delayed until the routing converges.

\begin{figure}
    \centering
    \includegraphics[width=\columnwidth]{baseline_throughput.pdf}
    \caption{Baseline Throughput Disruption}
    \label{fig:baseline_throughput}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=\columnwidth]{baseline_disruption.pdf}
    \caption{Baseline Disruption Timeline}
    \label{fig:baseline_disruption}
\end{figure}

These problems highlight the limitations of traditional routing-based approaches, such as NLSR, in handling frequent producer mobility. Addressing these issues effectively requires specialised mechanisms that can rapidly establish temporary communication paths without waiting for global routing convergence.

% ==============================================================================

\section{Controllable Flooding for NDN Mobility} 
\label{sec:solution}

To address the challenges of producer mobility in NDN, particularly in latency-sensitive applications such as video conferencing or live streaming, we propose \textit{OptoFlood}, a novel controllable flooding mechanism. OptoFlood rapidly establishes temporary bidirectional communication paths following producer movements and leverages these paths to accelerate routing convergence.

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{NDN_Producer_Mobility_Problem_Solution.pdf}
    \caption{NDN Producer Mobility Problem Solution}
    \label{fig:NDN Producer Mobility Problem Solution}
\end{figure}

\subsection{Producer Mobility Detection and Data Packet Flooding}
\label{sec:solution:data-flooding}

In our implementation, producer mobility is detected at the application layer (e.g., via interface-up events), and the producer marks subsequent Data packets to indicate a mobility event. Flooding is then executed by forwarders when they process such mobility-marked Data, rather than by the producer directly. \cite{FIXME}
%
Each mobility-marked Data packet carries the following markings:

\begin{itemize}
  \item \textbf{LP--MobilityFlag}: a hop-by-hop flag in the LP header used to identify mobility-related Data at forwarders. If a forwarder finds a matching PIT entry, it clears the flag and forwards the Data normally so that the return path proceeds through standard PIT-based forwarding.
  \item \textbf{LP--OptoHopLimit}: a hop-by-hop scope control decremented at each hop (default~3) to confine Data flooding to a local region. This field is experimental in our deployment and is distinct from the native Interest HopLimit.
  \item \textbf{Flood-ID}: an immutable identifier used for duplicate suppression in floods. In our implementation, FloodId is encoded as a Data MetaInfo extension TLV so that it is part of the signed portion of the Data and cannot be forged or altered by intermediate nodes.
  \item \textbf{NewFaceSeq}: an immutable sequence number used by forwarders to create or update a Temporary FIB (TFIB) entry upon receiving mobility-marked Data. NewFaceSeq is also carried in the signed portion of the Data (MetaInfo extension TLV) to ensure integrity.
\end{itemize}

At the forwarding plane, a forwarder treats a Data packet as OptoFlood-enabled when it detects FloodId/NewFaceSeq in the Data MetaInfo. The forwarder enforces duplicate suppression based on Flood-ID and applies a per-producer rate limit to bound overhead.

For dissemination, flooded Data packets \emph{first} follow available FIB next hops. If no valid FIB next hop exists, forwarders fall back to \emph{scoped expansion} over data-plane adjacent faces under LP--OptoHopLimit, excluding LOCAL faces and suppressing the incoming face (and any already satisfied faces) to avoid immediate loops. The aim is to reach a node that still holds a valid Pending Interest Table (PIT) entry along (or near) the original path so that the Data can be returned to the consumer without waiting for global routing updates.

\subsection{Forwarder-Triggered Interest Flooding}
\label{sec:solution:interest-flooding}

Interest flooding is also performed by the forwarder and is triggered only as a last resort. In our implementation, the flooding procedure is invoked on a Content Store miss when both the FIB and the TFIB provide no usable next hop for the Interest prefix.

The forwarder sets and enforces the native \emph{HopLimit} (default~3) before flooding (if not already present), decrementing it at each hop. Interest flooding is sent only to non-LOCAL faces.

To prevent repeated storms, each forwarder maintains a short-lived per node cache keyed by (Name, Nonce) so that the same Interest is flooded at most once per node within a small time window (about one second).

We also retain an explicit triggering path: if an Interest already carries a HopLimit, the forwarder may treat it as an explicit request to flood once even when a FIB entry exists, although the default consumer in our evaluation does not rely on this option.

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{Interest_Flooding.pdf}
    \caption{Interest Flooding}
    \label{fig:Interest Flooding}
\end{figure}

\subsection{Temporary Bidirectional Path Establishment}
\label{sec:solution:bidir}

A key goal of OptoFlood is to establish a temporary \emph{bidirectional} communication capability quickly after handover. In the downstream direction (consumer $\rightarrow$ producer), Interest flooding can locate a viable path toward the producer's new attachment point when unicast forwarding fails. In the upstream direction (producer $\rightarrow$ consumer), mobility-marked Data flooding increases the likelihood that Data corresponding to Interests issued shortly before handover can reach a forwarder that still maintains the appropriate PIT state.

In addition, forwarders opportunistically create short-lived forwarding hints via a \emph{Temporary FIB (TFIB)}. Upon receiving mobility-marked Data, a forwarder creates or updates a TFIB entry (separate from the standard FIB) mapping the relevant prefix to the incoming face, annotated with NewFaceSeq/FloodId, and with a short TTL (about one second). Subsequent Interests can then switch to unicast via TFIB immediately, reducing the need for repeated Interest flooding while global routing converges. \cite{FIXME}

\subsection{Accelerated Network Convergence}
\label{sec:solution:convergence}

OptoFlood integrates temporary flooding-based paths with faster global convergence via NLSR. When a forwarder successfully establishes or updates a TFIB entry, it triggers an NLSR management command at \texttt{/localhost/nlsr/fast-lsa/trigger}. This command installs a short-lived routing entry (Fast-LSA style) with an expiration period of approximately one second, and employs throttling (500~ms per prefix) and de-duplication (by Prefix+NewFaceSeq) to limit control-plane overhead. \cite{FIXME}
%
Regular periodic LSAs later supersede short-lived updates, and TFIB entries expire naturally.

\subsection{Security and Flooding Control}

To mitigate risks associated with flooding, OptoFlood uses complementary control mechanisms.

\textbf{Digital signatures for immutable fields.} NDN Data packets are signed; immutable fields such as Names, Content, and the MetaInfo extensions (e.g., FloodId/NewFaceSeq) are authenticated end-to-end. Dynamic hop-by-hop controls (\emph{LP--MobilityFlag}, \emph{LP--OptoHopLimit}) live in the LP header outside the signature so that intermediate nodes can legitimately decrement or clear them without breaking integrity checks on the Data itself.

\textbf{Scoped hop limits.} A small default hop limit (3) confines both Data and Interest flooding to a local region and prevents excessive scope. Packets exceeding the threshold are dropped.

\textbf{Rate limiting and duplicate suppression.} Forwarders enforce a per-producer flood rate limit (e.g. 100~packets/s for flooded traffic) and maintain a FloodId-based cache for duplicate suppression. Together these controls bound overhead and reduce the attack surface for denial-of-service attempts, while still allowing enough exploration to rescue pending Interests.

Together, these controls keep flooding local, short, and safe, while enabling rapid recovery in mobility events.

% ==============================================================================
\section{Evaluation}
\label{sec:evaluation}

We evaluated OptoFlood in real-time video-based mobility scenarios, representing common live conferencing and streaming applications.

% ------------------------------------------------------------------------------
\subsection{Methodology}

We focus on campus micro-mobility with real-time video: a smartphone user walks across a campus network, with the connection handing over between nearby Points of Attachment (PoAs) under the same distribution domain while the video stream remains active. This is a common, real-world scenario that must work effectively with NDN and is sensitive to latency, packet loss, and transient routing disruption.

% - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
\subsubsection{Producer Application}
We implement a typical NDN video producer with our mobility extensions.
Generated video Data packets have a freshness period of 10 seconds, permitting caching but preventing stale data from clogging the network, and carry a payload of synthetic data matching the size and timing of video content. The packets are digitally signed to ensure integrity and security.
Content prefixes are advertised via NLSR in the usual manner, with the extensions discussed in Section \ref{sec:solution}.

Upon detecting changes in its network attachment point, the producer marks the data packets associated with the mobility event to enable OptoFlood’s to control the flooding and acceleration of convergence. In our deployment, immutable identifiers used for flooding (e.g., Flood-ID and a sequence number for forwarding hints) are carried in signed Data MetaInfo extension TLVs, while hop-by-hop controls (e.g., mobility indication and scoped hop limits) are carried in the LP header and may be updated by intermediate forwarders.

% - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
\subsubsection{Consumer Application}

The consumer issues Interests every 33~ms (30~fps) with freshness and a 6~s lifetime, validates returned Data using a trust schema, and logs basic metrics.

% - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
\subsubsection{Network Topology}

The experiment simulates a handheld UE (e.g., a smartphone) in a campus network, maintaining a real-time video meeting while handing over between nearby Points of Attachment (PoAs) under the same distribution domain. Based on a typical walking speed of approximately 1.4~m/s and a PoA spacing of 60--80~m across roads and buildings, the UE performs a handover roughly every 45--60~seconds. This micro-mobility setting keeps movements local (within two to three hops) and provides a realistic basis for evaluating OptoFlood’s low-latency recovery after producer movements.

The network follows a classic three-layer mobile architecture representative of carrier xHaul deployments:
\begin{itemize}
    \item \textbf{Core layer:} One core switch, linking to the distribution layer with 1~Gbps bandwidth and 1~ms latency.
    \item \textbf{Distribution layer:} Two aggregation switches, each connected to the core and providing 500~Mbps / 1~ms links to their access layer.
    \item \textbf{Access layer:} Three access switches (PoAs) per aggregation switch, each offering 100~Mbps bandwidth and 10~ms latency to the UE.
\end{itemize}

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{Topology.pdf}
    \caption{Experiment Topology}
    \label{exp_topo}
\end{figure}

% - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
\subsubsection{Methodology}

Simulations were conducted using Mini-NDN version 0.7.0 and repeated with identical topology, applications, and mobility patterns, both with and without OptoFlood enhancements, to ensure that performance differences are attributable solely to the OptoFlood mechanism.

For each run, all network nodes were initialised with NFD and NLSR and allowed to reach a stable routing state (typically within 20~seconds). The consumer and producer applications were then launched simultaneously: the consumer periodically issued Interest packets for video segments, while the producer generated corresponding Data packets in real time, emulating a live video conference scenario.

Producer mobility was simulated by sequentially reattaching the producer node to different access switches (PoAs), with a stable interval between movements chosen to the 120~second hand-off period expected for a walking UE. Each hand-off was implemented by disconnecting from the current PoA and immediately connecting to the next, representing movement across coverage zones under the same distribution domain.

We record packet traces (\texttt{ndndump}) in three places: the consumer, the access switch adjacent to the old PoA, and the access switch adjacent to the new PoA for each hand-off.
The simulation runs as containers on a single host (an AMD EPYC server with 64 cores, 128 threads, 512GB memory, running Debian 12 ``bookworm''), so the clocks are consistent; where cross-node timing is required, we compute relative times from the consumer’s point of view.

% ------------------------------------------------------------------------------
\subsection{Results}

We evaluated OptoFlood using three metrics that capture user-perceived continuity, delivery reliability, and the safety of controlled flooding.
Metrics are computed for each hand-off, considering the window from 2~s before reattachment to 8~s after; we also report steady-state values outside this window.

\textbf{Service disruption time.}
We report per-handoff disruption times as a bar plot (baseline vs OptoFlood, side-by-side). We also report the median and the 90th percentile in all handoffs. This shows how quickly communication resumes after reattachment.

\begin{figure}
    \centering
    \includegraphics[width=\columnwidth]{solution_disruption.pdf}
    \caption{Solution Disruption}
    \label{fig:solution_disruption}
\end{figure}

\textbf{Unmet-Interest ratio.}
We computed the ratio within the analysis window for each handoff and showed a paired comparison (baseline vs OptoFlood). We also give the steady-state ratio outside the window as a reference. A lower ratio under OptoFlood indicates that pending Interests around the hand-off are satisfied with fewer retransmissions.
\begin{figure}
    \centering
    \includegraphics[width=\columnwidth]{baseline_loss.pdf}
    \caption{Baseline Loss}
    \label{fig:baseline_loss}
\end{figure}
\begin{figure}
    \centering
    \includegraphics[width=\columnwidth]{solution_loss.pdf}
    \caption{Solution Loss}
    \label{fig:solution_loss}
\end{figure}

\textbf{Flooding overhead and scope.}
We plotted the time series of flooded packets per second during the window and gave a small table with the observed hop span (min and max \textit{HopLimit} seen). We check that the configured hop limit is respected and that flooding stays within the configured bound.
\begin{figure}
    \centering
    \includegraphics[width=\columnwidth]{baseline_overhead.pdf}
    \caption{Baseline Overhead}
    \label{fig:baseline_overhead}
\end{figure}
\begin{figure}
    \centering
    \includegraphics[width=\columnwidth]{solution_overhead.pdf}
    \caption{Solution Overhead}
    \label{fig:solution_overhead}
\end{figure}

Together, these results demonstrate that mobility introduces a clear disruption under baseline NDN, while OptoFlood reduces the disruption time and unmet requests with bounded, localised flooding.

% ==============================================================================

\section{Related Work}
\label{sec:related}

The management of producer mobility in NDN has attracted significant research attention. Various solutions have emerged, generally categorised according to their underlying mechanisms. Here, we summarise three representative approaches—KITE, AFIRM, and MAP-Me—and highlight their respective strengths and limitations.

\textbf{KITE} \cite{zhang:2018:kite} is a trace-based mobility support scheme that leverages an immobile rendezvous point and the stateful NDN forwarding plane. A mobile producer maintains soft state by exchanging authenticated Interest/Data messages that establish a hop-by-hop trace toward its latest attachment point, allowing subsequent Interests to follow the trace after reaching the rendezvous point. This approach reduces the reliance on slow global routing convergence and keeps data retrieval largely transparent to applications. However, KITE introduces a dependency on a reachable rendezvous point and periodic signalling to refresh soft state, which can become a scalability concern under frequent mobility or large numbers of mobile producers.

\textbf{AFIRM (Adaptive Forwarding-based Link Recovery for Mobility)} \cite{meddeb:2018:afirm} addresses producer mobility by repairing forwarding behaviour through adaptive forwarding and local recovery, aiming to re-establish usable paths without introducing a permanent anchor. By reacting to mobility-induced disruptions and adjusting forwarding decisions, AFIRM can reduce service interruption for localised micro-mobility. However, its effectiveness depends on the timely detection and stability of local recovery in highly dynamic conditions; frequent mobility may also introduce additional signalling and forwarding overhead.

\textbf{MAP-Me (Managing Anchor-less Producer Mobility)} \cite{auge:2016:map-me} provides anchor-less mobility support by handling producer location updates in the data plane. Upon producer movement, MAP-Me propagates update information hop-by-hop to re-direct affected forwarding paths, avoiding the delays associated with purely routing-plane convergence. MAP-Me is therefore well-suited to latency-sensitive micro-mobility scenarios. However, in frequent or high-intensity mobility, repeated updates can generate noticeable overhead and may require careful tuning to balance responsiveness against network cost.

In terms of route updates, KITE maintains soft-state traces rooted at a rendezvous point, while AFIRM focusses on local forwarding recovery, and MAP-Me proactively updates forwarding state in the data plane upon movement. All three differ fundamentally from baseline NDN deployments where producer relocation requires routing-plane updates (e.g., NLSR prefix re-advertisement) and subsequent global convergence.

\textbf{MoQ/QUICR (Media over QUIC)} \cite{jennings:2022:quicr-arch} proposes a relay-assisted publish/subscribe architecture over QUIC for low-latency media delivery. Producers publish named media objects, and consumers subscribe; relays can cache and fan out objects. Mobility is handled primarily via endpoint re-attachment (e.g., QUIC connection migration and re-subscription), offering fast application-level continuity. However, this is an overlay design: it does not rely on the PIT/ FIF state of NDN in the network, nor does it provide an in the network mechanism to rescue pending requests along disrupted forwarding paths after producer movement. Thus, MoQ/QUICR shares NDN-like ideas (naming and caching), but targets a different layer and problem scope.

In comparison, our OptoFlood solution offers a flood-based mechanism specifically designed for dynamic producer mobility scenarios, employing controlled flooding of \emph{both} Data and Interest packets immediately following producer movement. Unlike KITE, OptoFlood does not depend on a rendezvous/anchor node, avoiding central dependency in the forwarding workflow. Compared to AFIRM and MAP-Me, which focus on forwarding recovery or explicit update propagation, OptoFlood prioritises \emph{immediate} temporary reachability: (i) mobility-marked Data packets are locally flooded to rescue pending Interests on the old path, and (ii) forwarders trigger scoped Interest flooding when forwarding state is missing, to rapidly discover the producer’s new attachment point. Once a working face is confirmed, forwarders install short-lived TFIB state to quickly cut back to unicast. Finally, OptoFlood couples these temporary paths with the routing plane by triggering a short-lived, locally scoped Fast-LSA update via NLSR, accelerating convergence while allowing normal NLSR advertisements to eventually take over.

% ==============================================================================

\section{Conclusions}
\label{sec:conclusion}

This paper presented \textit{OptoFlood}, a controllable flooding mechanism for producer mobility in Named Data Networking. OptoFlood addresses the key weakness of routing-based mobility handling: after a producer handover, forwarding state and routing information can remain stale for seconds, during which Interests may be discarded and Data may fail to return along invalidated reverse paths. Rather than waiting for global convergence, OptoFlood provides immediate localised recovery by establishing temporary bidirectional reachability and then accelerating routing convergence through lightweight integration with NLSR.

OptoFlood combines two complementary mechanisms. First, mobility-marked \emph{Data packet flooding} disseminates Data generated around a handover with bounded scope and duplicate suppression, improving the likelihood that pending Interests issued before the move are satisfied without relying on global route updates. Second, \emph{Interest packet flooding} is triggered by forwarders only as a last resort, when both FIB and TFIB provide no usable next hop, and is confined by native hop limits and per-node de-duplication. Intermediate forwarders opportunistically install short-lived TFIB hints to quickly revert subsequent Interests back to unicast forwarding once a viable face is observed. Finally, OptoFlood couples these temporary paths to the control plane via a Fast-LSA trigger, installing short-lived routing entries through NLSR to shorten the overall convergence period while allowing standard NLSR advertisements to eventually take over.

Overall, OptoFlood aims to keep mobility recovery \emph{local, short-lived, and explicitly bounded}: flooding is scoped (hop-limited), suppressed (duplicate filtering), and constrained (rate limiting), while cryptographic integrity is preserved by keeping immutable identifiers inside signed Data MetaInfo extensions and leaving hop-by-hop controls in the LP header for in-network processing. These design choices make OptoFlood practical for latency-sensitive micro-mobility settings, where rapid continuity matters and mobility events occur frequently enough that waiting for global convergence alone is insufficient.

\subsection{Long Term Impact Assessment}

\subsubsection{Continuous optimisation of network performance}
\begin{itemize}
    \item \textbf{Efficiency Improvements:} Because OptoFlood restores temporary reachability quickly after handover, it can reduce the duration of ``blind'' retransmission phases where consumers repeatedly re-express Interests while forwarding state is stale. Over time, this can translate into smoother application performance and fewer bursts of recovery traffic during mobility.
    \item \textbf{Enhanced Reliability:} By providing a mechanism to rescue pending Interests and by enabling forwarders to cache short-lived forwarding hints (TFIB), the network becomes more resilient to transient disruptions caused by producer relocation, especially when mobility remains local (within a few hops) and frequent.
\end{itemize}

\subsubsection{Resource Usage and Network Stability}
\begin{itemize}
    \item \textbf{Resource Optimization:} OptoFlood is based on explicitly bounded flooding with a short lifetime. TFIB entries and Fast-LSA updates are also short-lived, limiting long-term state growth and reducing the risk of persistent routing pollution. This provides a pragmatic balance between rapid recovery and overhead.
    \item \textbf{Stability Analysis:} Although flooding is controlled, its interaction with retransmission behaviour, caching, and routing updates can influence stability under high load or dense mobility. The throttling and de-duplication mechanisms in both the forwarding plane (FloodId/Nonce caches, rate limits) and the routing plane (Fast-LSA throttling) are therefore essential to prevent oscillation and excessive control traffic, and should be considered carefully in larger deployments.
\end{itemize}

% ==============================================================================

\section*{Acknowledgements}

This work was supported in part by Rakuten Mobile.

% ==============================================================================

\bibliographystyle{IEEEtran}
\bibliography{OptoFlood}
\end{document}

